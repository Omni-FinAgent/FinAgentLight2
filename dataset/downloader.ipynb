{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gnews Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news from: https://gnews.io/api/v4/search?q=Google%20Pixel&lang=en&max=5&apikey=a91fd1a70f894c56afe397fc0ac1c074&country=us&from=2022-09-01&to=2022-09-30\n",
      "Title: Samsung Galaxy S25 Ultra vs Google Pixel 9 Pro XL: A friendly but heated rivalry\n",
      "Description: Here's a look ahead at Google's recently announced Pixel 9 Pro XL and how it might compare to the more distant Galaxy S25 Ultra from Samsung.\n",
      "Published At: 2025-01-22T18:00:16Z\n",
      "Source: PhoneArena\n",
      "URL: https://www.phonearena.com/reviews/galaxy-s25-ultra-vs-pixel-9-pro-xl_id6440\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Gemini gets multi-action commands, Astra on Pixel & Galaxy S25\n",
      "Description: As part of Samsung’s Galaxy S25 launch, Google announced the latest Android, Circle to Search, and Gemini app features...\n",
      "Published At: 2025-01-22T18:00:00Z\n",
      "Source: 9to5Google\n",
      "URL: https://9to5google.com/2025/01/22/gemini-samsung-galaxy-s25-launch/\n",
      "--------------------------------------------------------------------------------\n",
      "Title: This Samsung-like Google Wallet shortcut might be coming to your Pixel\n",
      "Description: Double tap the power button for wallet\n",
      "Published At: 2025-01-22T17:56:23Z\n",
      "Source: Android Police\n",
      "URL: https://www.androidpolice.com/android-16-google-wallet-power-button-shortcut/\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Why I may finally switch from Pixel to Samsung Galaxy this year - and it's Google's fault\n",
      "Description: The Samsung Galaxy S25 Ultra may be the best Google Pixel alternative in 2025, especially with the software improvements.\n",
      "Published At: 2025-01-22T16:00:00Z\n",
      "Source: ZDNet\n",
      "URL: https://www.zdnet.com/article/why-i-may-finally-switch-from-pixel-to-samsung-galaxy-this-year-and-its-googles-fault/\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Why you should go with Google\n",
      "Description: As Samsung debuts its new Galaxy S25, you should consider buying a Google Pixel phone instead. Gemini AI will always be better on a Pixel.\n",
      "Published At: 2025-01-22T15:09:00Z\n",
      "Source: BGR\n",
      "URL: https://bgr.com/tech/google-pixel-phone-ai-features-competition/\n",
      "--------------------------------------------------------------------------------\n",
      "Saved 5 articles to ./gnews_data\\news_20250123_055903.json\n",
      "Articles saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhous\\AppData\\Local\\Temp\\ipykernel_15204\\717930138.py:86: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "from urllib.parse import quote\n",
    "from urllib.error import HTTPError, URLError\n",
    "from datetime import datetime\n",
    "from typing import Optional, List\n",
    "\n",
    "\n",
    "class GNewsDownloader:\n",
    "    def __init__(self,\n",
    "                 api_key: Optional[str] = None,\n",
    "                 query: Optional[str] = None,\n",
    "                 lang: str = \"en\",\n",
    "                 country: Optional[str] = None,\n",
    "                 start_date: Optional[str] = None,\n",
    "                 end_date: Optional[str] = None,\n",
    "                 max_results: int = 10,\n",
    "                 workdir: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        初始化 GNewsDownloader\n",
    "        \"\"\"\n",
    "        self.api_key = api_key or os.getenv(\"GNEWS_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"API key is required. Please set it via parameter or GNEWS_API_KEY environment variable.\")\n",
    "        \n",
    "        self.query = query\n",
    "        if not self.query:\n",
    "            raise ValueError(\"Query parameter is required.\")\n",
    "        \n",
    "        self.lang = lang\n",
    "        self.country = country\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.max_results = max_results\n",
    "\n",
    "        # 工作目录\n",
    "        self.workdir = workdir or \"./gnews_data\"\n",
    "        if not os.path.exists(self.workdir):\n",
    "            os.makedirs(self.workdir)\n",
    "        if not os.access(self.workdir, os.W_OK):\n",
    "            raise ValueError(f\"Work directory {self.workdir} is not writable.\")\n",
    "\n",
    "        # 构建URL\n",
    "        self.base_url = \"https://gnews.io/api/v4/search\"\n",
    "        self.request_url = self._build_request_url()\n",
    "\n",
    "    def _build_request_url(self) -> str:\n",
    "        \"\"\"\n",
    "        构建请求 URL，包含查询参数、语言、国家和时间区间。\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}?q={quote(self.query)}&lang={self.lang}&max={self.max_results}&apikey={self.api_key}\"\n",
    "        if self.country:\n",
    "            url += f\"&country={self.country}\"\n",
    "        if self.start_date:\n",
    "            url += f\"&from={self.start_date}\"\n",
    "        if self.end_date:\n",
    "            url += f\"&to={self.end_date}\"\n",
    "        return url\n",
    "\n",
    "    def fetch_news(self) -> List[dict]:\n",
    "        \"\"\"\n",
    "        从 GNews API 获取新闻数据\n",
    "        \"\"\"\n",
    "        print(f\"Fetching news from: {self.request_url}\")\n",
    "        try:\n",
    "            with urllib.request.urlopen(self.request_url) as response:\n",
    "                data = json.loads(response.read().decode(\"utf-8\"))\n",
    "                return data.get(\"articles\", [])\n",
    "        except HTTPError as e:\n",
    "            print(f\"HTTP Error: {e.code} - {e.reason}\")\n",
    "        except URLError as e:\n",
    "            print(f\"URL Error: {e.reason}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "        return []\n",
    "\n",
    "    def save_news(self, articles: List[dict]) -> bool:\n",
    "        \"\"\"\n",
    "        保存新闻数据到本地 JSON 文件\n",
    "        \"\"\"\n",
    "        if not articles:\n",
    "            print(\"No articles to save.\")\n",
    "            return False\n",
    "\n",
    "        timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        file_path = os.path.join(self.workdir, f\"news_{timestamp}.json\")\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                json.dump(articles, file, ensure_ascii=False, indent=4)\n",
    "            print(f\"Saved {len(articles)} articles to {file_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving articles: {e}\")\n",
    "            return False\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        主流程：获取新闻并保存到本地\n",
    "        \"\"\"\n",
    "        articles = self.fetch_news()\n",
    "        if articles:\n",
    "            for article in articles:\n",
    "                print(f\"Title: {article['title']}\")\n",
    "                print(f\"Description: {article['description']}\")\n",
    "                print(f\"Published At: {article['publishedAt']}\")\n",
    "                print(f\"Source: {article['source']['name']}\")\n",
    "                print(f\"URL: {article['url']}\")\n",
    "                print(\"-\" * 80)\n",
    "            if self.save_news(articles):\n",
    "                print(\"Articles saved successfully.\")\n",
    "            else:\n",
    "                print(\"Failed to save articles.\")\n",
    "        else:\n",
    "            print(\"No articles fetched.\")\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    API_KEY = \"a91fd1a70f894c56afe397fc0ac1c074\"\n",
    "\n",
    "    gnews_downloader = GNewsDownloader(\n",
    "        api_key=API_KEY,\n",
    "        query=\"Google Pixel\",\n",
    "        lang=\"en\",\n",
    "        country=\"us\",\n",
    "        start_date=\"2022-09-01\",  # 开始日期\n",
    "        end_date=\"2022-09-30\",    # 结束日期\n",
    "        max_results=5,\n",
    "        workdir=\"./gnews_data\"\n",
    "    )\n",
    "\n",
    "    gnews_downloader.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google News Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news from: https://www.searchapi.io/api/v1/search\n",
      "Request successful!\n",
      "Saved news data to cache: ./cache\\Jeff_Bezos_news_20250123.json\n",
      "Title: A Decade Ago, Jeff Bezos Bought a Newspaper. Now He’s Paying Attention to It Again. (Published 2023)\n",
      "Source: The New York Times\n",
      "Date: Jul 22, 2023\n",
      "URL: https://www.nytimes.com/2023/07/22/business/media/jeff-bezos-washington-post.html\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Amazon recreated the garage where Jeff Bezos started the company in 1994. Here's what it looks like.\n",
      "Source: AboutAmazon.com\n",
      "Date: Oct 18, 2023\n",
      "URL: https://www.aboutamazon.com/news/workplace/first-amazon-office-jeff-bezos-garage\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Exclusive | Billionaire Jeff Bezos engaged to Lauren Sánchez after nearly 5 years together\n",
      "Source: Page Six\n",
      "Date: May 22, 2023\n",
      "URL: https://pagesix.com/2023/05/22/jeff-bezos-engaged-to-lauren-sanchez-after-nearly-5-years-together/\n",
      "--------------------------------------------------------------------------------\n",
      "Title: A decade ago, Jeff Bezos bought a newspaper. Now he’s paying attention to it again.\n",
      "Source: Editor and Publisher\n",
      "Date: Jul 24, 2023\n",
      "URL: https://www.editorandpublisher.com/stories/a-decade-ago-jeff-bezos-bought-a-newspaper-now-hes-paying-attention-to-it-again,244885\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Jeff Bezos, after founding Amazon in a Seattle garage three decades ago, packs his bags for Miami\n",
      "Source: AP News\n",
      "Date: Nov 3, 2023\n",
      "URL: https://apnews.com/article/jeff-bezos-leaves-seattle-miami-amazon-0f04558aa909f1f5b56735e82a0a2011\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "class GoogleNewsDownloader:\n",
    "    def __init__(self,\n",
    "                 api_key: str,\n",
    "                 query: str,\n",
    "                 max_results: int = 10,\n",
    "                 start_date: str = None,\n",
    "                 end_date: str = None,\n",
    "                 cache_dir: str = \"./cache\"):\n",
    "        \"\"\"\n",
    "        初始化 GoogleNewsDownloader\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.query = query\n",
    "        self.max_results = max_results\n",
    "        self.start_date = start_date  # 格式: MM/DD/YYYY\n",
    "        self.end_date = end_date  # 格式: MM/DD/YYYY\n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "        # API 基础 URL\n",
    "        self.base_url = \"https://www.searchapi.io/api/v1/search\"\n",
    "\n",
    "        # 确保缓存目录存在\n",
    "        if not os.path.exists(self.cache_dir):\n",
    "            os.makedirs(self.cache_dir)\n",
    "        if not os.access(self.cache_dir, os.W_OK):\n",
    "            raise ValueError(f\"Cache directory {self.cache_dir} is not writable.\")\n",
    "\n",
    "    def _get_cache_path(self) -> str:\n",
    "        \"\"\"\n",
    "        根据查询生成缓存文件路径\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%d\")\n",
    "        filename = f\"{self.query.replace(' ', '_')}_{timestamp}.json\"\n",
    "        return os.path.join(self.cache_dir, filename)\n",
    "\n",
    "    def fetch_news(self) -> dict:\n",
    "        \"\"\"\n",
    "        从 Google News API 获取新闻数据\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            \"engine\": \"google_news\",\n",
    "            \"q\": self.query,\n",
    "            \"num\": self.max_results,\n",
    "            \"api_key\": self.api_key\n",
    "        }\n",
    "\n",
    "        # 如果设置了时间范围，加入到参数中\n",
    "        if self.start_date:\n",
    "            params[\"time_period_min\"] = self.start_date\n",
    "        if self.end_date:\n",
    "            params[\"time_period_max\"] = self.end_date\n",
    "\n",
    "        print(f\"Fetching news from: {self.base_url}\")\n",
    "        try:\n",
    "            response = requests.get(self.base_url, params=params, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                print(\"Request successful!\")\n",
    "                return response.json()\n",
    "            else:\n",
    "                print(f\"Request failed with status code: {response.status_code}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred during the request: {e}\")\n",
    "        return None\n",
    "\n",
    "    def save_to_cache(self, data: dict):\n",
    "        \"\"\"\n",
    "        将新闻数据保存到缓存文件\n",
    "        \"\"\"\n",
    "        cache_path = self._get_cache_path()\n",
    "        try:\n",
    "            with open(cache_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "            print(f\"Saved news data to cache: {cache_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save cache: {e}\")\n",
    "\n",
    "    def load_from_cache(self) -> dict:\n",
    "        \"\"\"\n",
    "        从缓存文件加载新闻数据\n",
    "        \"\"\"\n",
    "        cache_path = self._get_cache_path()\n",
    "        if os.path.exists(cache_path):\n",
    "            print(f\"Using cached data from: {cache_path}\")\n",
    "            try:\n",
    "                with open(cache_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    return json.load(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load cache: {e}\")\n",
    "        return None\n",
    "\n",
    "    def process_news(self, news_data: dict):\n",
    "        \"\"\"\n",
    "        处理并打印新闻数据\n",
    "        \"\"\"\n",
    "        if not news_data or \"organic_results\" not in news_data:\n",
    "            print(\"No news data available.\")\n",
    "            return\n",
    "\n",
    "        for article in news_data[\"organic_results\"]:\n",
    "            print(f\"Title: {article.get('title')}\")\n",
    "            print(f\"Source: {article.get('source')}\")\n",
    "            print(f\"Date: {article.get('date')}\")\n",
    "            print(f\"URL: {article.get('link')}\")\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        主流程：尝试从缓存加载数据，若缓存不存在则从 API 获取\n",
    "        \"\"\"\n",
    "        # 尝试从缓存加载数据\n",
    "        news_data = self.load_from_cache()\n",
    "        if not news_data:\n",
    "            # 如果缓存不可用，则从 API 获取数据\n",
    "            news_data = self.fetch_news()\n",
    "            if news_data:\n",
    "                # 保存数据到缓存\n",
    "                self.save_to_cache(news_data)\n",
    "\n",
    "        # 处理新闻数据\n",
    "        self.process_news(news_data)\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    # 替换为你的 Google News API 密钥\n",
    "    API_KEY = \"jTKr1YDvcC2PBUAtFmSRsk7q\"\n",
    "\n",
    "    # 初始化下载器\n",
    "    downloader = GoogleNewsDownloader(\n",
    "        api_key=API_KEY,\n",
    "        query=\"Jeff Bezos news\",  # 查询关键字\n",
    "        max_results=5,  # 每次请求的最大新闻数量\n",
    "        start_date=\"01/01/2023\",  # 搜索的开始时间（格式: MM/DD/YYYY）\n",
    "        end_date=\"12/31/2023\",  # 搜索的结束时间（格式: MM/DD/YYYY）\n",
    "        cache_dir=\"./cache\"  # 缓存目录\n",
    "    )\n",
    "\n",
    "    # 运行下载器\n",
    "    downloader.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newsapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news from: https://newsapi.org/v2/everything?q=Google%20Pixel&language=en&sortBy=popularity&pageSize=5&apiKey=9dfa4228ed7f4f7e8522d1ef7d9fb6b2&from=2025-01-01&to=2025-01-23\n",
      "Title: Google Pixel 4a's update kills its battery life on purpose\n",
      "Description: Google’s Pixel 4a has long been considered a great smartphone for those on a budget\n",
      ", but it just received a software update that calls that into question. The update lowers the reported battery life\n",
      ". This isn’t a side-effect of some new software. This is …\n",
      "Published At: 2025-01-08T16:45:32Z\n",
      "Source: Yahoo Entertainment\n",
      "URL: https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_e1bb03c5-a7c3-47a0-b6ee-1f32e8153ea0\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Hisense introduces its first-ever consumer microLED TV\n",
      "Description: Hisense just introduced its first consumer microLED television at CES 2025 in Las Vegas. The 136MX includes a high-density array of over 24.88 microscopic LEDs to “deliver unparalleled brightness, resolution, and precision.” As with all microLED displays, eac…\n",
      "Published At: 2025-01-06T19:40:57Z\n",
      "Source: Yahoo Entertainment\n",
      "URL: https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_45a2a2f9-5c1a-4ead-87d3-0b9a2040c973\n",
      "--------------------------------------------------------------------------------\n",
      "Saved 2 articles to ./news_data\\news_20250123_074956.json\n",
      "Articles saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhous\\AppData\\Local\\Temp\\ipykernel_15204\\1886125406.py:87: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "from urllib.parse import quote\n",
    "from urllib.error import HTTPError, URLError\n",
    "from datetime import datetime\n",
    "from typing import Optional, List\n",
    "\n",
    "\n",
    "class NewsAPIDownloader:\n",
    "    def __init__(self,\n",
    "                 api_key: Optional[str] = None,\n",
    "                 query: Optional[str] = None,\n",
    "                 lang: str = \"en\",\n",
    "                 from_date: Optional[str] = None,\n",
    "                 to_date: Optional[str] = None,\n",
    "                 sort_by: str = \"publishedAt\",\n",
    "                 max_results: int = 10,\n",
    "                 workdir: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        初始化 NewsAPIDownloader\n",
    "        \"\"\"\n",
    "        self.api_key = api_key or os.getenv(\"NEWS_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"API key is required. Please set it via parameter or NEWS_API_KEY environment variable.\")\n",
    "        \n",
    "        self.query = query\n",
    "        if not self.query:\n",
    "            raise ValueError(\"Query parameter is required.\")\n",
    "        \n",
    "        self.lang = lang\n",
    "        self.from_date = from_date\n",
    "        self.to_date = to_date\n",
    "        self.sort_by = sort_by\n",
    "        self.max_results = max_results\n",
    "\n",
    "        # 工作目录\n",
    "        self.workdir = workdir or \"./news_data\"\n",
    "        if not os.path.exists(self.workdir):\n",
    "            os.makedirs(self.workdir)\n",
    "        if not os.access(self.workdir, os.W_OK):\n",
    "            raise ValueError(f\"Work directory {self.workdir} is not writable.\")\n",
    "\n",
    "        # 构建URL\n",
    "        self.base_url = \"https://newsapi.org/v2/everything\"\n",
    "        self.request_url = self._build_request_url()\n",
    "\n",
    "    def _build_request_url(self) -> str:\n",
    "        \"\"\"\n",
    "        构建请求 URL，包含查询参数、语言和时间区间。\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}?q={quote(self.query)}&language={self.lang}&sortBy={self.sort_by}&pageSize={self.max_results}&apiKey={self.api_key}\"\n",
    "        if self.from_date:\n",
    "            url += f\"&from={self.from_date}\"\n",
    "        if self.to_date:\n",
    "            url += f\"&to={self.to_date}\"\n",
    "        return url\n",
    "\n",
    "    def fetch_news(self) -> List[dict]:\n",
    "        \"\"\"\n",
    "        从 News API 获取新闻数据\n",
    "        \"\"\"\n",
    "        print(f\"Fetching news from: {self.request_url}\")\n",
    "        try:\n",
    "            with urllib.request.urlopen(self.request_url) as response:\n",
    "                data = json.loads(response.read().decode(\"utf-8\"))\n",
    "                if data.get(\"status\") == \"ok\":\n",
    "                    return data.get(\"articles\", [])\n",
    "                else:\n",
    "                    print(f\"Error in response: {data.get('message')}\")\n",
    "        except HTTPError as e:\n",
    "            print(f\"HTTP Error: {e.code} - {e.reason}\")\n",
    "        except URLError as e:\n",
    "            print(f\"URL Error: {e.reason}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "        return []\n",
    "\n",
    "    def save_news(self, articles: List[dict]) -> bool:\n",
    "        \"\"\"\n",
    "        保存新闻数据到本地 JSON 文件\n",
    "        \"\"\"\n",
    "        if not articles:\n",
    "            print(\"No articles to save.\")\n",
    "            return False\n",
    "\n",
    "        timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        file_path = os.path.join(self.workdir, f\"news_{timestamp}.json\")\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                json.dump(articles, file, ensure_ascii=False, indent=4)\n",
    "            print(f\"Saved {len(articles)} articles to {file_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving articles: {e}\")\n",
    "            return False\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        主流程：获取新闻并保存到本地\n",
    "        \"\"\"\n",
    "        articles = self.fetch_news()\n",
    "        if articles:\n",
    "            for article in articles:\n",
    "                print(f\"Title: {article['title']}\")\n",
    "                print(f\"Description: {article['description']}\")\n",
    "                print(f\"Published At: {article['publishedAt']}\")\n",
    "                print(f\"Source: {article['source']['name']}\")\n",
    "                print(f\"URL: {article['url']}\")\n",
    "                print(\"-\" * 80)\n",
    "            if self.save_news(articles):\n",
    "                print(\"Articles saved successfully.\")\n",
    "            else:\n",
    "                print(\"Failed to save articles.\")\n",
    "        else:\n",
    "            print(\"No articles fetched.\")\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    API_KEY = \"9dfa4228ed7f4f7e8522d1ef7d9fb6b2\"\n",
    "\n",
    "    news_downloader = NewsAPIDownloader(\n",
    "        api_key=API_KEY,\n",
    "        query=\"Google Pixel\",\n",
    "        lang=\"en\",\n",
    "        from_date=\"2025-01-01\",  # 开始日期\n",
    "        to_date=\"2025-01-23\",    # 结束日期\n",
    "        sort_by=\"popularity\",    # 排序方式\n",
    "        max_results=5,           # 最大结果数\n",
    "        workdir=\"./news_data\"    # 工作目录\n",
    "    )\n",
    "\n",
    "    news_downloader.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finagent_light",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
